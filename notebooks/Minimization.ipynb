{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9b59b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from iminuit import Minuit\n",
    "from scipy.stats import norm\n",
    "from scipy.optimize import fmin, fmin_bfgs,minimize, curve_fit, SR1,BFGS\n",
    "from scipy.stats import rv_continuous\n",
    "from iminuit.util import describe, make_func_code\n",
    "import numpy as np\n",
    "import math\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f96f65",
   "metadata": {},
   "source": [
    "## Iminuit example\n",
    "\n",
    "We will make a \"classical\" example starting from the scikit-hep package iminuit!\n",
    "\n",
    "This together with other packages can be found in the page scikit-hep:\n",
    "\n",
    "https://scikit-hep.org/\n",
    "\n",
    "The documentation specific to iminuit can be found here:\n",
    "\n",
    "https://iminuit.readthedocs.io/en/stable/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ddd732",
   "metadata": {},
   "source": [
    "## Step 1: metrics\n",
    "\n",
    "Any minimization, or \"fit procedure\", requires a metrics to minimize. \n",
    "\n",
    "Iminuit allows to customize this metrics, by defining an ad-hoc class, while"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "71884186",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's first define the metrics, simple chi2 \n",
    "def chi2(model,x,y,sigma,*par):\n",
    "    return ((model(x,*par)-y)/sigma)**2\n",
    "\n",
    "class leastsquares:\n",
    "    def __init__(self,model,xs,ys,sigmas):# here I initialize the class with a constructor \n",
    "        self.model=model\n",
    "        self.xs=xs\n",
    "        self.ys=ys\n",
    "        self.sigmas=sigmas\n",
    "    def __call__(self, *par):# once I initialized I can call the class as a function of the arguments *par\n",
    "        chitot=0\n",
    "        for i in range(len(self.xs)):\n",
    "            chitot=chitot+chi2(self.model,self.xs[i],self.ys[i],self.sigmas[i],*par)\n",
    "        return chitot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0fb724e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define metrics: negative log likelihood\n",
    "class nll:\n",
    "    def __init__(self,model,x):\n",
    "        self.x=x\n",
    "        self.model=model\n",
    "    def __call__(self, *par):\n",
    "        return np.sum([-2*math.log(self.model(xi,*par)) for xi in self.x])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "75506317",
   "metadata": {},
   "outputs": [],
   "source": [
    "class gaussian_gen(rv_continuous):#this is how inheritance is set up in python:\n",
    "#here gaussian_gen inherits all methods from the class rv_continuous of scipy stats\n",
    "    \n",
    "    def set_pars(self,mean,sigma):#define a custom method to set some parameters\n",
    "        self.mean=mean\n",
    "        self.sigma=sigma\n",
    "    \n",
    "    def _pdf(self, x):#here I implement the concrete version of the abstract method _pdf, which evaluates the probability density \n",
    "        return np.exp(-(x-self.mean)**2 / (2.*self.sigma**2)) / (self.sigma*np.sqrt(2.0 * np.pi))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02968ab7",
   "metadata": {},
   "source": [
    "## Let's setup the functions\n",
    "1. Linear fit\n",
    "2. Gaussian fit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e7ca406c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple Fitting procedure!\n"
     ]
    }
   ],
   "source": [
    "print(\"Simple Fitting procedure!\")\n",
    "\n",
    "\n",
    "#Linear function      \n",
    "linear = lambda x,a,b : a+b*x\n",
    "gaussian = lambda x,mu,sigma : 1/(sigma*np.sqrt(2*math.pi)) * np.exp(-(x-mu)*(x-mu) / (2* sigma*sigma) )\n",
    "\n",
    "#Those are equivalent to:\n",
    "def linear_func(x,a,b):\n",
    "    return a +b*x\n",
    "def gaussian_func (x,mu,sigma,n):\n",
    "    return 1/(sigma*math.sqrt(2*math.pi)) * math.exp(-(x-mu)*(x-mu) / (2* sigma*sigma) )\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27fa84be",
   "metadata": {},
   "source": [
    "# Example #1.1 linear fit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "66496013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " xs  [0, 1.1, 4]  ys 1  [1.9749851899761586, 3.1381985334168094, 5.975916062984427]  ys 2  [2.120372715685266, 3.153197295694041, 6.028613510339177]\n",
      "0.2664904697894054\n",
      "printing all parameters from minuit minimization\n",
      "┌───┬──────┬───────────┬───────────┬────────────┬────────────┬─────────┬─────────┬───────┐\n",
      "│   │ Name │   Value   │ Hesse Err │ Minos Err- │ Minos Err+ │ Limit-  │ Limit+  │ Fixed │\n",
      "├───┼──────┼───────────┼───────────┼────────────┼────────────┼─────────┼─────────┼───────┤\n",
      "│ 0 │ x0   │   2.00    │   0.08    │            │            │         │         │       │\n",
      "│ 1 │ x1   │   0.996   │   0.034   │            │            │         │         │       │\n",
      "└───┴──────┴───────────┴───────────┴────────────┴────────────┴─────────┴─────────┴───────┘\n",
      "printing covariance matrix\n",
      "┌────┬───────────────────┐\n",
      "│    │       x0       x1 │\n",
      "├────┼───────────────────┤\n",
      "│ x0 │  0.00672 -0.00199 │\n",
      "│ x1 │ -0.00199  0.00117 │\n",
      "└────┴───────────────────┘\n",
      "to get the values and errors use .values and .print \n",
      "<ValueView x0=2.0034904709685324 x1=0.9958094849945743>\n",
      "<ErrorView x0=0.08195979965011436 x1=0.034219297284438455>\n",
      "Now printing the scipy minimum with scipi.optimize.fmin_bfgs (array([2.00349047, 0.99580948]), 0.24753338594988478, array([-2.38604844e-06,  9.48086381e-07]), array([[ 0.92105185, -0.28797957],\n",
      "       [-0.28797957,  0.09033221]]), 15, 5, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27275/465287786.py:29: IMinuitWarning: errordef not set, using 1 (appropriate for least-squares)\n",
      "  m1.migrad()\n"
     ]
    }
   ],
   "source": [
    "a=2\n",
    "b=1\n",
    " \n",
    "#let's make some numbers \n",
    "xsm=[0,1.1,4]\n",
    "xss=[.1,.1,.1]\n",
    "    \n",
    "    \n",
    "#norm comes from scipy \n",
    "#normfunction = norm(mean,sigma) rvs means random variates: returns a random value according to the pdf.\n",
    "ys=[linear(norm(x[0],x[1]).rvs(),a,b) for x in zip(xsm,xss)] #We generate ys from the parameters a and b, but by fluctuating them.\n",
    "#this is the equivalent to:\n",
    "ys2=[]\n",
    "for i in range(len(xsm)):\n",
    "    xmean_i=xsm[i]\n",
    "    sigma_i=xss[i]\n",
    "        \n",
    "    random_x=norm(xmean_i,sigma_i).rvs()\n",
    "    yi= linear(random_x,a,b)\n",
    "    ys2.append(yi)\n",
    "\n",
    "print(\" xs \", xsm , \" ys 1 \", ys , \" ys 2 \",ys2)\n",
    "    \n",
    "ls=leastsquares(linear,xsm,ys,xss)\n",
    "    \n",
    "print(ls(a,b))#this uses the __call__ function inside of a class\n",
    "    \n",
    "m1 = Minuit(ls,a,b) #now I add a minimizing algorithm, for example minuit\n",
    "m1.migrad()\n",
    "m1.hesse()\n",
    "    \n",
    "    \n",
    "scipy_min= fmin(lambda args:ls(args[0],args[1]) , [a,b],full_output=True, disp=False)\n",
    "#this is one option, but doesn't evaluate hessian\n",
    "    \n",
    "scipy_min= fmin_bfgs(lambda args:ls(args[0],args[1]) , [a,b],full_output=True, disp=False)\n",
    "#this option evaluates hessian\n",
    "    \n",
    "#now printing all values\n",
    "print(\"printing all parameters from minuit minimization\")\n",
    "print ( m1.params )\n",
    "print(\"printing covariance matrix\")\n",
    "print ( m1.covariance )\n",
    "\n",
    "#to get the parameters and the errors you do:\n",
    "print (\"to get the values and errors use .values and .print \")\n",
    "print ( m1.values )\n",
    "print ( m1.errors )\n",
    "\n",
    "print(\"Now printing the scipy minimum with scipi.optimize.fmin_bfgs\", scipy_min)\n",
    "#note this is a different minimization method! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b7a573",
   "metadata": {},
   "source": [
    "## Fit sanity checks \n",
    "How do I understand if the fit works?\n",
    "\n",
    "#1) Have a figure of merit, or a metrics for the fit quality\n",
    "#2) Perform bias tests: if the fit has some bias in the obtaned parameters\n",
    "\n",
    "if the fit works correctly, then usually the parameter is centered around the fitted value with a variance = error^2 \n",
    "\n",
    "# In practice:\n",
    "\n",
    "Perform the fit several  times  by having data - or pseudo-data to fluctuate according to their pdf.\n",
    "\n",
    "In this case means : generate a lot of fits!\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1ce82256",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27275/2652031955.py:8: IMinuitWarning: errordef not set, using 1 (appropriate for least-squares)\n",
      "  m_i.migrad()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pulls mean is:  -0.008562582790703743\n",
      "pluss standard deviation is :  1.0075460101010472\n"
     ]
    }
   ],
   "source": [
    "#I generate a lot of pseudoexperiments:\n",
    "pulls_a=[]\n",
    "pulls_b=[]\n",
    "for i in range(1000):\n",
    "    y_i=[linear(norm(x[0],x[1]).rvs(),a,b) for x in zip(xsm,xss)] \n",
    "    ls_i = leastsquares(linear, xsm,y_i,xss)\n",
    "    m_i = Minuit(ls_i,a,b) \n",
    "    m_i.migrad()\n",
    "    m_i.migrad()\n",
    "    m_i.hesse()\n",
    "    #        print(\" a \", a, \"m_i \",m_i.values[0])\n",
    "    pull_a_i = (a-m_i.values[0])/m_i.errors[0]\n",
    "    pulls_a.append(pull_a_i)\n",
    "\n",
    "print(\"pulls mean is: \" ,np.mean(pulls_a))#numpy mean \n",
    "print(\"pluss standard deviation is : \",np.std(pulls_a))#numpy) standard deviation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9258bc94",
   "metadata": {},
   "source": [
    "# Example 1.2: Gaussian fit: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4e3f3d9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125646.75995076615\n",
      "# Generated points: 1000  mean  104.02680362060646  error on the mean  0.30975896701352307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27275/2495418940.py:29: IMinuitWarning: errordef not set, using 1 (appropriate for least-squares)\n",
      "  m2.migrad()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "covmatrix ┌────┬───────────────────┐\n",
      "│    │       x0       x1 │\n",
      "├────┼───────────────────┤\n",
      "│ x0 │   0.0959 1.11e-05 │\n",
      "│ x1 │ 1.11e-05   0.0479 │\n",
      "└────┴───────────────────┘\n",
      "printing all parameters from minuit minimization\n",
      "┌───┬──────┬───────────┬───────────┬────────────┬────────────┬─────────┬─────────┬───────┐\n",
      "│   │ Name │   Value   │ Hesse Err │ Minos Err- │ Minos Err+ │ Limit-  │ Limit+  │ Fixed │\n",
      "├───┼──────┼───────────┼───────────┼────────────┼────────────┼─────────┼─────────┼───────┤\n",
      "│ 0 │ x0   │  104.03   │   0.31    │   -0.31    │    0.31    │         │         │       │\n",
      "│ 1 │ x1   │   9.79    │   0.22    │   -0.21    │    0.22    │         │         │       │\n",
      "└───┴──────┴───────────┴───────────┴────────────┴────────────┴─────────┴─────────┴───────┘\n",
      "printing covariance matrix\n",
      "┌────┬───────────────────┐\n",
      "│    │       x0       x1 │\n",
      "├────┼───────────────────┤\n",
      "│ x0 │   0.0959 1.11e-05 │\n",
      "│ x1 │ 1.11e-05   0.0479 │\n",
      "└────┴───────────────────┘\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "    \n",
    "#We could use a gaussian defined like this\n",
    "gau=gaussian_gen(a=-1000,b=1000,name=\"custom_gaussian\") \n",
    "gau.set_pars(mean=104,sigma=10)\n",
    "values=[]\n",
    "for i in range(10):\n",
    "    values.append(gau.rvs() )\n",
    "    \n",
    "#Norm is more efficient:\n",
    "values=norm(104,10).rvs(1000)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "nbins = 20\n",
    "ax.hist(values,nbins)\n",
    "plt.savefig(\"gaussian_example.png\")\n",
    "\n",
    "\n",
    "#Define the NLL function\n",
    "nl=nll(gaussian,values)\n",
    "mu = 50\n",
    "sigma = 5\n",
    "print(nl(mu,sigma))\n",
    "\n",
    "#Check some of the features:\n",
    "mea=np.mean(values)\n",
    "ndof= 1\n",
    "print (\"# Generated points:\",len(values),\" mean \", mea,\" error on the mean \",np.std(values,ddof=ndof)/math.sqrt(len(values)))\n",
    "       \n",
    "m2 = Minuit(nl,mu,sigma)\n",
    "m2.migrad()\n",
    "m2.hesse()\n",
    "m2.minos()\n",
    "print(\"covmatrix\",m2.covariance)\n",
    "\n",
    "\n",
    "print(\"printing all parameters from minuit minimization\")\n",
    "print ( m2.params )\n",
    "print(\"printing covariance matrix\")\n",
    "print ( m2.covariance )\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de57009",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
